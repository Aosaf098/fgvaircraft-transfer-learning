{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9483d3ce",
   "metadata": {},
   "source": [
    "### Assignment 2 Understanding transfer learning and fine tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03187ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Torch infos: 2.10.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets\n",
    "import os \n",
    "import numpy as np \n",
    "from typing import Literal\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f\"[INFO] Torch infos: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5535c",
   "metadata": {},
   "source": [
    "# We need transform from resnet18 and its weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb11434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ResNet18_Weights.DEFAULT.transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e681a3e",
   "metadata": {},
   "source": [
    "# pick a dataset  you can import from\n",
    "\n",
    "```python\n",
    "from torchvision import datasets\n",
    "```\n",
    "\n",
    "# Easy picks:\n",
    "\n",
    "- Food101\n",
    "- Flowers102\n",
    "- DTD\n",
    "- FGVAircraft\n",
    "\n",
    "# Other picks:\n",
    "\n",
    "```python\n",
    "\n",
    "full_train = datasets.OxfordIIITPet(root=\"data\", split=\"trainval\", download=True, transform=transform)\n",
    "test_ds    = datasets.OxfordIIITPet(root=\"data\", split=\"test\", download=True, transform=transform)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb9128e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6667\n"
     ]
    }
   ],
   "source": [
    "full_train = datasets.FGVCAircraft('../Dataset', split=\"trainval\", transform=transform, download=True)\n",
    "test_ds = datasets.FGVCAircraft('../Dataset', split=\"test\", download=True, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9644c7a",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de646ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 5333\n",
      "Validation Size: 1334\n",
      "Train and Validation Ds <torch.utils.data.dataset.Subset object at 0x000001CB66A32610> <torch.utils.data.dataset.Subset object at 0x000001CB6634EB90>\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "train_size = int(len(full_train) * train_ratio)\n",
    "\n",
    "validation_size = len(full_train) - train_size\n",
    "\n",
    "train_ds, validation_ds = random_split(full_train, [train_size, validation_size])\n",
    "\n",
    "print(\"Train Size:\", train_size)\n",
    "print(\"Validation Size:\", validation_size)\n",
    "print(\"Train and Validation Ds\", train_ds, validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81494df3",
   "metadata": {},
   "source": [
    "# load the train, validation and test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23237671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5333 samples\n",
      "Validation set size: 1334 samples\n",
      "Test set size: 3333 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Training set size: {len(train_ds)} samples\")\n",
    "print(f\"Validation set size: {len(validation_ds)} samples\")\n",
    "print(f\"Test set size: {len(test_ds)} samples\")\n",
    "\n",
    "assert len(train_ds) + len(validation_ds) == len(full_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7d34de",
   "metadata": {},
   "source": [
    "# create dataloader handler from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aecd097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "validation_loader = DataLoader(validation_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faaba75",
   "metadata": {},
   "source": [
    "# now create the cnn, use the resnet18 as backbone, and ResNet18_Weights as initial weights.\n",
    "- create the backbone\n",
    "- create a classifier \n",
    "- based on your dataset add the correct number of output classes\n",
    "- the classifier have to be trainable.\n",
    "\n",
    "# Question 1?\n",
    "- Why we freeze the backbone? Why not the classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0eea2",
   "metadata": {},
   "source": [
    "# add the train evaluation, and predict functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b6506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a3fe8c5",
   "metadata": {},
   "source": [
    "### Phase 1: Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba96147",
   "metadata": {},
   "source": [
    "# freeze all layers except the classifier.\n",
    "- train and evaluate the model for 50 epochs \n",
    "- remember to save val loss and train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770fba3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a232ace",
   "metadata": {},
   "source": [
    "# Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0cc015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f1fac57",
   "metadata": {},
   "source": [
    "# plot predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0be5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5870efa9",
   "metadata": {},
   "source": [
    "# calculate TEST accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e33c99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f792c955",
   "metadata": {},
   "source": [
    "# Calculate confusion matrices precision and recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4bfcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04e9246e",
   "metadata": {},
   "source": [
    "### Phase 2: Freeze layer 4 - Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e747ec4",
   "metadata": {},
   "source": [
    "# from the freezed cnn unfreeze the  ``` layer4 ```. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e471d8",
   "metadata": {},
   "source": [
    "# Train for 50 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac75948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "697bf91b",
   "metadata": {},
   "source": [
    "# Plot curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e99d597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "027fb601",
   "metadata": {},
   "source": [
    "# visualize prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b55bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7278848",
   "metadata": {},
   "source": [
    "# Calculate test accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836e999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c68f5498",
   "metadata": {},
   "source": [
    "# calculate confusion matrix precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486c0e9c",
   "metadata": {},
   "source": [
    "# Question 2 What did you learn? What is the difference between transfer learning and fine tuning? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvsf-2 (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
